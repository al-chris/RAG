{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preface: chunking\n",
    "\n",
    "we don't explicitly cover document chunking/splitting.\n",
    "\n",
    "For an excelent review of document chunking, see the video from Greg Kamradt\n",
    "\n",
    "https://www.youtube.com/watch?v=8OJC21T2SL4\n",
    "\n",
    "Paper:\n",
    "https://arxiv.org/abs/2312.06648"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = 'true'\n",
    "\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = 'https://api.smith.langchain.com'\n",
    "\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv('LANGCHAIN_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 12: Multi-representation Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "docs = loader.load()\n",
    "\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2024-02-05-human-data-quality/\")\n",
    "docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FIDELIS ALIU\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to batch ingest runs: LangSmithConnectionError('Connection error caused failure to POST https://api.smith.langchain.com/runs/batch  in LangSmith API. Please confirm your internet connection.. ConnectTimeout(MaxRetryError(\"HTTPSConnectionPool(host=\\'api.smith.langchain.com\\', port=443): Max retries exceeded with url: /runs/batch (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000029009242300>, \\'Connection to api.smith.langchain.com timed out. (connect timeout=10.0)\\'))\"))')\n",
      "Failed to batch ingest runs: LangSmithConnectionError('Connection error caused failure to POST https://api.smith.langchain.com/runs/batch  in LangSmith API. Please confirm your internet connection.. ConnectTimeout(MaxRetryError(\"HTTPSConnectionPool(host=\\'api.smith.langchain.com\\', port=443): Max retries exceeded with url: /runs/batch (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000029009243650>, \\'Connection to api.smith.langchain.com timed out. (connect timeout=10.0)\\'))\"))')\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "chain = (\n",
    "    {\"doc\": lambda x: x.page_content}\n",
    "    | ChatPromptTemplate.from_template(\"Summarize the following document:\\n\\n{doc}\")\n",
    "    | ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", google_api_key=os.getenv(\"GEMINI_API_KEY\"), temperature=0)\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "summaries = chain.batch(docs, {\"max_concurrency\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This document explores the concept of LLM-powered autonomous agents, which are systems that use large language models (LLMs) as their core controllers. It delves into the key components of these agents, including planning, memory, and tool use.\\n\\n**Planning:**\\n\\n* **Task Decomposition:** LLMs can break down complex tasks into smaller, manageable subgoals using techniques like Chain of Thought (CoT) and Tree of Thoughts.\\n* **Self-Reflection:** Agents can learn from past actions and refine their plans through self-criticism and self-reflection. Examples include ReAct, Reflexion, and Chain of Hindsight.\\n\\n**Memory:**\\n\\n* **Types of Memory:** The document draws parallels between human memory types (sensory, short-term, and long-term) and LLM capabilities.\\n* **Maximum Inner Product Search (MIPS):** External vector stores are used for long-term memory, enabling fast retrieval of information using approximate nearest neighbors (ANN) algorithms like LSH, ANNOY, HNSW, FAISS, and ScaNN.\\n\\n**Tool Use:**\\n\\n* **External APIs:** LLMs can be augmented with external tools and APIs to access information and capabilities beyond their pre-trained knowledge. Examples include MRKL, TALM, Toolformer, ChatGPT Plugins, OpenAI API function calling, and HuggingGPT.\\n* **API-Bank:** This benchmark evaluates the performance of tool-augmented LLMs by assessing their ability to call, retrieve, and plan API usage.\\n\\n**Case Studies:**\\n\\n* **Scientific Discovery Agent:** ChemCrow demonstrates how LLMs can be combined with domain-specific tools for tasks in organic synthesis, drug discovery, and materials design.\\n* **Generative Agents Simulation:** This experiment simulates virtual characters controlled by LLM-powered agents, showcasing emergent social behavior and interactions.\\n\\n**Proof-of-Concept Examples:**\\n\\n* **AutoGPT:** This project demonstrates the potential of LLMs to act autonomously, but it faces reliability issues due to the natural language interface.\\n* **GPT-Engineer:** This project aims to generate code repositories based on natural language instructions, showcasing the ability of LLMs to understand and implement complex tasks.\\n\\n**Challenges:**\\n\\n* **Finite Context Length:** The limited context window of LLMs restricts their ability to process long histories, detailed instructions, and complex API interactions.\\n* **Long-Term Planning:** LLMs struggle with long-term planning and task decomposition, particularly when dealing with unexpected errors.\\n* **Reliability of Natural Language Interface:** The reliance on natural language for communication between LLMs and other components can lead to formatting errors and unpredictable behavior.\\n\\nThe document concludes by highlighting the potential of LLM-powered autonomous agents while acknowledging the challenges that need to be addressed for their widespread adoption.\\n',\n",
       " \"This document explores the importance of high-quality human data in deep learning model training, focusing on the challenges and strategies for collecting, evaluating, and utilizing such data. \\n\\n**Key Takeaways:**\\n\\n* **Human Raters and Data Quality:** The document highlights the importance of careful task design, rater selection and training, and data aggregation techniques to ensure high-quality human annotations.\\n* **The Wisdom of the Crowd:** It discusses the use of crowdsourcing platforms like Amazon Mechanical Turk for data annotation, emphasizing the need for weighting schemes to mitigate spammers and the potential for non-experts to contribute valuable insights.\\n* **Rater Agreement:** The document explores various methods for measuring rater agreement, including majority voting, raw agreement, Cohen's Kappa, and probabilistic graph modeling. It emphasizes the importance of identifying and mitigating spammers.\\n* **Rater Disagreement and Two Paradigms:** The document acknowledges that disagreement among raters is not always bad, especially in subjective domains. It presents two contrasting paradigms for data annotation: descriptive (embracing diversity) and prescriptive (encouraging consistency).\\n* **Data Quality and Model Training:** The document explores techniques for identifying mislabeled data during model training, including influence functions, prediction changes during training, and noisy cross-validation.\\n* **Influence Functions:** This technique measures the effect of individual data points on model parameters and loss function, allowing for the identification of influential (potentially mislabeled) data points.\\n* **Prediction Changes during Training:** By tracking model prediction changes during training, methods like Data Maps and forgetting analysis can identify hard-to-learn samples, which may indicate mislabeled data.\\n* **Noisy Cross-Validation:** This method iteratively identifies clean and noisy samples by comparing predictions from models trained on different subsets of the data.\\n\\n**Overall, the document provides a comprehensive overview of the challenges and strategies for ensuring high-quality human data in deep learning, emphasizing the need for careful consideration of rater agreement, disagreement, and the impact of data quality on model training.** \\n\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.storage import InMemoryByteStore\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "\n",
    "# The vectorstore to use to index the child chunks\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"summaries\",\n",
    "    embedding_function=GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\", google_api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    ")\n",
    "\n",
    "# The storage layer for the parent documents\n",
    "store = InMemoryByteStore()\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "# The retriever\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    byte_store=store,\n",
    "    id_key=id_key,\n",
    ")\n",
    "doc_ids = [str(uuid.uuid4()) for _ in docs]\n",
    "\n",
    "# Docs linked to summaries\n",
    "summary_docs = [\n",
    "    Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
    "    for i, s in enumerate(summaries)\n",
    "]\n",
    "\n",
    "# Add\n",
    "retriever.vectorstore.add_documents(summary_docs)\n",
    "retriever.docstore.mset(list(zip(doc_ids, docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'doc_id': 'ce8c89b7-b69f-451a-98e0-8dfd85935b21'}, page_content='This document explores the concept of LLM-powered autonomous agents, which are systems that use large language models (LLMs) as their core controllers. It delves into the key components of these agents, including planning, memory, and tool use.\\n\\n**Planning:**\\n\\n* **Task Decomposition:** LLMs can break down complex tasks into smaller, manageable subgoals using techniques like Chain of Thought (CoT) and Tree of Thoughts.\\n* **Self-Reflection:** Agents can learn from past actions and refine their plans through self-criticism and self-reflection. Examples include ReAct, Reflexion, and Chain of Hindsight.\\n\\n**Memory:**\\n\\n* **Types of Memory:** The document draws parallels between human memory types (sensory, short-term, and long-term) and LLM capabilities.\\n* **Maximum Inner Product Search (MIPS):** External vector stores are used for long-term memory, enabling fast retrieval of information using approximate nearest neighbors (ANN) algorithms like LSH, ANNOY, HNSW, FAISS, and ScaNN.\\n\\n**Tool Use:**\\n\\n* **External APIs:** LLMs can be augmented with external tools and APIs to access information and capabilities beyond their pre-trained knowledge. Examples include MRKL, TALM, Toolformer, ChatGPT Plugins, OpenAI API function calling, and HuggingGPT.\\n* **API-Bank:** This benchmark evaluates the performance of tool-augmented LLMs by assessing their ability to call, retrieve, and plan API usage.\\n\\n**Case Studies:**\\n\\n* **Scientific Discovery Agent:** ChemCrow demonstrates how LLMs can be combined with domain-specific tools for tasks in organic synthesis, drug discovery, and materials design.\\n* **Generative Agents Simulation:** This experiment simulates virtual characters controlled by LLM-powered agents, showcasing emergent social behavior and interactions.\\n\\n**Proof-of-Concept Examples:**\\n\\n* **AutoGPT:** This project demonstrates the potential of LLMs to act autonomously, but it faces reliability issues due to the natural language interface.\\n* **GPT-Engineer:** This project aims to generate code repositories based on natural language instructions, showcasing the ability of LLMs to understand and implement complex tasks.\\n\\n**Challenges:**\\n\\n* **Finite Context Length:** The limited context window of LLMs restricts their ability to process long histories, detailed instructions, and complex API interactions.\\n* **Long-Term Planning:** LLMs struggle with long-term planning and task decomposition, particularly when dealing with unexpected errors.\\n* **Reliability of Natural Language Interface:** The reliance on natural language for communication between LLMs and other components can lead to formatting errors and unpredictable behavior.\\n\\nThe document concludes by highlighting the potential of LLM-powered autonomous agents while acknowledging the challenges that need to be addressed for their widespread adoption.\\n')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Memory in agents\"\n",
    "\n",
    "sub_docs = vectorstore.similarity_search(query, k=1)\n",
    "sub_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FIDELIS ALIU\\AppData\\Local\\Temp\\ipykernel_10868\\494825069.py:1: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use invoke instead.\n",
      "  retrieved_docs = retriever.get_relevant_documents(query, n_results=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\n\\n\\n\\nLLM Powered Autonomous Agents | Lil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPosts\\n\\n\\n\\n\\nArchive\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\nTags\\n\\n\\n\\n\\nFAQ\\n\\n\\n\\n\\nemojisearch.app\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\n \\n\\n\\nTable of Contents\\n\\n\\n\\nAgent System Overview\\n\\nComponent One: Planning\\n\\nTask Decomposition\\n\\nSelf-Reflection\\n\\n\\nComponent Two: Memory\\n\\nTypes of Memory\\n\\nMaximum Inner Product Search (MIPS)\\n\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs = retriever.get_relevant_documents(query, n_results=1)\n",
    "retrieved_docs[0].page_content[0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 13: RAPTOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=jbGchdTL7d0\n",
    "\n",
    "Paper:\n",
    "https://arxiv.org/abs/2401.18059"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 14: ColBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://colbert.aiserv.cloud/\n",
    "https://tim.simonwillison.net/llms/colbert-ragatouille\n",
    "https://thenewstack.io/overcoming-the-limits-of-rag-with-colbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U ragatouille"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FIDELIS ALIU\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\FIDELIS ALIU\\.cache\\huggingface\\hub\\models--colbert-ir--colbertv2.0. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 18, 05:26:52] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FIDELIS ALIU\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "c:\\Users\\FIDELIS ALIU\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\cpp_extension.py:380: UserWarning: Error checking compiler version for cl: [WinError 2] The system cannot find the file specified\n",
      "  warnings.warn(f'Error checking compiler version for {compiler}: {error}')\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['where', 'cl']' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragatouille\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RAGPretrainedModel\n\u001b[1;32m----> 2\u001b[0m RAG \u001b[38;5;241m=\u001b[39m \u001b[43mRAGPretrainedModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolbert-ir/colbertv2.0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\FIDELIS ALIU\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ragatouille\\RAGPretrainedModel.py:71\u001b[0m, in \u001b[0;36mRAGPretrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, n_gpu, verbose, index_root)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load a ColBERT model from a pre-trained checkpoint.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \n\u001b[0;32m     61\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;124;03m    cls (RAGPretrainedModel): The current instance of RAGPretrainedModel, with the model initialised.\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     70\u001b[0m instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m()\n\u001b[1;32m---> 71\u001b[0m instance\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mColBERT\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_gpu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_root\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m instance\n",
      "File \u001b[1;32mc:\\Users\\FIDELIS ALIU\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ragatouille\\models\\colbert.py:84\u001b[0m, in \u001b[0;36mColBERT.__init__\u001b[1;34m(self, pretrained_model_name_or_path, n_gpu, index_name, verbose, load_from_index, training_mode, index_root, **kwargs)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mroot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_root\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m training_mode:\n\u001b[1;32m---> 84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference_ckpt \u001b[38;5;241m=\u001b[39m \u001b[43mCheckpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolbert_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model_max_tokens \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     88\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference_ckpt\u001b[38;5;241m.\u001b[39mbert\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmax_position_embeddings\n\u001b[0;32m     89\u001b[0m     ) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_context \u001b[38;5;241m=\u001b[39m Run()\u001b[38;5;241m.\u001b[39mcontext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_config)\n",
      "File \u001b[1;32mc:\\Users\\FIDELIS ALIU\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\colbert\\modeling\\checkpoint.py:19\u001b[0m, in \u001b[0;36mCheckpoint.__init__\u001b[1;34m(self, name, colbert_config, verbose)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, colbert_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, verbose:\u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m---> 19\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolbert_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m=\u001b[39m verbose\n",
      "File \u001b[1;32mc:\\Users\\FIDELIS ALIU\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\colbert\\modeling\\colbert.py:24\u001b[0m, in \u001b[0;36mColBERT.__init__\u001b[1;34m(self, name, colbert_config)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(name, colbert_config)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_gpu \u001b[38;5;241m=\u001b[39m colbert_config\u001b[38;5;241m.\u001b[39mtotal_visible_gpus \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 24\u001b[0m \u001b[43mColBERT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_load_torch_extensions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_gpu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolbert_config\u001b[38;5;241m.\u001b[39mmask_punctuation:\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskiplist \u001b[38;5;241m=\u001b[39m {w: \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     28\u001b[0m                      \u001b[38;5;28;01mfor\u001b[39;00m symbol \u001b[38;5;129;01min\u001b[39;00m string\u001b[38;5;241m.\u001b[39mpunctuation\n\u001b[0;32m     29\u001b[0m                      \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m [symbol, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_tokenizer\u001b[38;5;241m.\u001b[39mencode(symbol, add_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]]}\n",
      "File \u001b[1;32mc:\\Users\\FIDELIS ALIU\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\colbert\\modeling\\colbert.py:39\u001b[0m, in \u001b[0;36mColBERT.try_load_torch_extensions\u001b[1;34m(cls, use_gpu)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     38\u001b[0m print_message(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 39\u001b[0m segmented_maxsim_cpp \u001b[38;5;241m=\u001b[39m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msegmented_maxsim_cpp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpathlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;18;43m__file__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msegmented_maxsim.cpp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_cflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-O3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCOLBERT_LOAD_TORCH_EXTENSION_VERBOSE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFalse\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTrue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39msegmented_maxsim \u001b[38;5;241m=\u001b[39m segmented_maxsim_cpp\u001b[38;5;241m.\u001b[39msegmented_maxsim_cpp\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_extensions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\FIDELIS ALIU\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\cpp_extension.py:1312\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[0;32m   1220\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(name,\n\u001b[0;32m   1221\u001b[0m          sources: Union[\u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m]],\n\u001b[0;32m   1222\u001b[0m          extra_cflags\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1230\u001b[0m          is_standalone\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1231\u001b[0m          keep_intermediates\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1232\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1233\u001b[0m \u001b[38;5;124;03m    Load a PyTorch C++ extension just-in-time (JIT).\u001b[39;00m\n\u001b[0;32m   1234\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1310\u001b[0m \u001b[38;5;124;03m        ...     verbose=True)\u001b[39;00m\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_jit_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1314\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43msources\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_cflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_ldflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_include_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_get_build_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_cuda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_python_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_standalone\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_intermediates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_intermediates\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\FIDELIS ALIU\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\cpp_extension.py:1722\u001b[0m, in \u001b[0;36m_jit_compile\u001b[1;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[0;32m   1718\u001b[0m                 hipified_sources\u001b[38;5;241m.\u001b[39madd(hipify_result[s_abs]\u001b[38;5;241m.\u001b[39mhipified_path \u001b[38;5;28;01mif\u001b[39;00m s_abs \u001b[38;5;129;01min\u001b[39;00m hipify_result \u001b[38;5;28;01melse\u001b[39;00m s_abs)\n\u001b[0;32m   1720\u001b[0m             sources \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(hipified_sources)\n\u001b[1;32m-> 1722\u001b[0m         \u001b[43m_write_ninja_file_and_build_library\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1723\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1724\u001b[0m \u001b[43m            \u001b[49m\u001b[43msources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1725\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_cflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_cflags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1726\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1727\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_ldflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_ldflags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1728\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_include_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_include_paths\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1729\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuild_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1730\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1731\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_cuda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_cuda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1732\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_standalone\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_standalone\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1733\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m verbose:\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo modifications detected for re-loaded extension \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1735\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, skipping build step...\u001b[39m\u001b[38;5;124m'\u001b[39m, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstderr)\n",
      "File \u001b[1;32mc:\\Users\\FIDELIS ALIU\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\cpp_extension.py:1821\u001b[0m, in \u001b[0;36m_write_ninja_file_and_build_library\u001b[1;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_standalone)\u001b[0m\n\u001b[0;32m   1818\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmitting ninja build file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbuild_file_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[0;32m   1819\u001b[0m \u001b[38;5;66;03m# NOTE: Emitting a new ninja build file does not cause re-compilation if\u001b[39;00m\n\u001b[0;32m   1820\u001b[0m \u001b[38;5;66;03m# the sources did not change, so it's ok to re-emit (and it's fast).\u001b[39;00m\n\u001b[1;32m-> 1821\u001b[0m \u001b[43m_write_ninja_file_to_build_library\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuild_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1824\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1825\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_cflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_cflags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1826\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1827\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_ldflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_ldflags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1828\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_include_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_include_paths\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1829\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwith_cuda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_cuda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1830\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_standalone\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_standalone\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1832\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[0;32m   1833\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBuilding extension module \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstderr)\n",
      "File \u001b[1;32mc:\\Users\\FIDELIS ALIU\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\cpp_extension.py:2246\u001b[0m, in \u001b[0;36m_write_ninja_file_to_build_library\u001b[1;34m(path, name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, with_cuda, is_standalone)\u001b[0m\n\u001b[0;32m   2243\u001b[0m ext \u001b[38;5;241m=\u001b[39m EXEC_EXT \u001b[38;5;28;01mif\u001b[39;00m is_standalone \u001b[38;5;28;01melse\u001b[39;00m LIB_EXT\n\u001b[0;32m   2244\u001b[0m library_target \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m-> 2246\u001b[0m \u001b[43m_write_ninja_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2247\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2248\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2249\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpost_cflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcuda_cflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcuda_flags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcuda_post_cflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcuda_dlink_post_cflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2253\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobjects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mldflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mldflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlibrary_target\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlibrary_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwith_cuda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_cuda\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\FIDELIS ALIU\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\cpp_extension.py:2382\u001b[0m, in \u001b[0;36m_write_ninja_file\u001b[1;34m(path, cflags, post_cflags, cuda_cflags, cuda_post_cflags, cuda_dlink_post_cflags, sources, objects, ldflags, library_target, with_cuda)\u001b[0m\n\u001b[0;32m   2380\u001b[0m link_rule \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrule link\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m   2381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m IS_WINDOWS:\n\u001b[1;32m-> 2382\u001b[0m     cl_paths \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwhere\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2383\u001b[0m \u001b[43m                                        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;241m*\u001b[39mSUBPROCESS_DECODE_ARGS)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   2384\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cl_paths) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   2385\u001b[0m         cl_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(cl_paths[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\FIDELIS ALIU\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py:466\u001b[0m, in \u001b[0;36mcheck_output\u001b[1;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    463\u001b[0m         empty \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    464\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m empty\n\u001b[1;32m--> 466\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m           \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstdout\n",
      "File \u001b[1;32mc:\\Users\\FIDELIS ALIU\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py:571\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    569\u001b[0m     retcode \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mpoll()\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m retcode:\n\u001b[1;32m--> 571\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, process\u001b[38;5;241m.\u001b[39margs,\n\u001b[0;32m    572\u001b[0m                                  output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr)\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m CompletedProcess(process\u001b[38;5;241m.\u001b[39margs, retcode, stdout, stderr)\n",
      "\u001b[1;31mCalledProcessError\u001b[0m: Command '['where', 'cl']' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "from ragatouille import RAGPretrainedModel\n",
    "RAG = RAGPretrainedModel.from_pretrained(\"colbert-ir/colbertv2.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "def get_wikipedia_page(title: str):\n",
    "    \"\"\"\n",
    "    Retrieve the full text content of a Wikipedia page.\n",
    "    \n",
    "    :param title: str - Title of the Wikipedia page.\n",
    "    :return: str - full text content of the page as raw string\n",
    "    \"\"\"\n",
    "\n",
    "    # Wikipeia API endpoint\n",
    "    URL = \"https://en.wikipedia.org/w/api.php\"\n",
    "\n",
    "    # Parameters for the API request\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"format\": \"json\",\n",
    "        \"titles\": title,\n",
    "        \"prop\": \"extracts\",\n",
    "        \"explaintext\": True,\n",
    "        \n",
    "    }\n",
    "\n",
    "    # Custom User-Agent header to comply with Wikipedia's best practices\n",
    "    headers = {\"User-Agent\": \"RAGatouille_tutorial/0.0.1 (ben@clavie.eu)\"}\n",
    "\n",
    "    response = requests.get(URL, params=params, headers=headers)\n",
    "    data = response.json()\n",
    "\n",
    "    # Extrating page content\n",
    "    page = next(iter(data[\"query\"][\"pages\"].values()))\n",
    "\n",
    "    return page[\"extract\"] if \"extract\" in page else None\n",
    "\n",
    "full_document = get_wikipedia_page(\"Hayao Miyazaki\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAG.index(\n",
    "    collection=[full_document],\n",
    "    index_name=\"Miyazaki-123\",\n",
    "    max_document_length=100,\n",
    "    split_documents=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = RAG.search(query=\"What animation studio did Miyazaki found?\", k=3)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = RAG.as_langchain_retriever(k=3)\n",
    "retriever.invoke(\"What animation studio did Miyazaki found?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
